# Registro de Decisiones Arquitect√≥nicas (ADR)
## Sistema Retador v2.0

**Fecha de inicio**: Diciembre 2025  
**Estado**: Activo  
**√öltima actualizaci√≥n**: Integraci√≥n selectiva de propuestas V7

---

## √çndice de Decisiones

| ID      | T√≠tulo                                         | Estado    | Fecha    |
| ------- | ---------------------------------------------- | --------- | -------- |
| ADR-001 | Arquitectura Monolito Modular                  | Aceptada  | Dic 2024 |
| ADR-002 | Strategy Pattern para C√°lculos por Sharp       | Aceptada  | Dic 2024 |
| ADR-003 | F√≥rmula de Cuota M√≠nima                        | Aceptada  | Dic 2024 |
| ADR-004 | Redis para Deduplicaci√≥n (sin Bloom Filter)    | Aceptada  | Dic 2024 |
| ADR-005 | Chain of Responsibility para Validaci√≥n        | Aceptada  | Dic 2024 |
| ADR-006 | Multi-Bot Telegram con Heap Priorizado         | Aceptada  | Dic 2024 |
| ADR-007 | Persistencia PostgreSQL Diferida               | Diferida  | Dic 2024 |
| ADR-008 | Value Objects para Datos de Dominio            | Aceptada  | Dic 2024 |
| ADR-009 | Cursor Incremental para API                    | Aceptada  | Dic 2024 |
| ADR-010 | Polling Adaptativo con Backoff                 | Aceptada  | Dic 2024 |
| ADR-011 | Cache HTML en Message Formatter                | Aceptada  | Dic 2024 |
| ADR-012 | Rechazo de Bloom Filter                        | Rechazada | Dic 2024 |
| ADR-013 | Rechazo de Fire-and-Forget Redis               | Rechazada | Dic 2024 |
| ADR-014 | Procesamiento con asyncio.gather (sin workers) | Aceptada  | Dic 2024 |
| ADR-015 | Filtrado en Origen (API Parameters)            | Aceptada  | Dic 2024 |
| ADR-016 | Sistema de Suscripciones Automatizado          | Propuesta | Dic 2024 |

---

## ADR-001: Arquitectura Monolito Modular

### Estado
**Aceptada**

### Contexto
El sistema actual (v6) es un script monol√≠tico de ~1500 l√≠neas con todas las responsabilidades mezcladas. Necesitamos escalar a un sistema profesional, mantenible y testeable.

### Decisi√≥n
Adoptamos **Monolito Modular** con Clean Architecture (Domain, Application, Infrastructure).

### Justificaci√≥n
- Volumen actual (200-500 picks/hora) no justifica microservicios
- La latencia es la ventaja competitiva principal
- Un solo proceso facilita monitoreo y despliegue
- Estructura modular permite migrar a microservicios si es necesario

### Consecuencias
**Positivas**: Despliegue simple, latencia interna ~0ms, debugging simple
**Negativas**: Escala vertical, fallo total si el proceso muere

---

## ADR-002: Strategy Pattern para C√°lculos por Sharp

### Estado
**Aceptada**

### Contexto
Actualmente solo usamos Pinnacle como sharp, pero el sistema debe soportar m√∫ltiples sharps en el futuro.

### Decisi√≥n
Implementar **Strategy Pattern** para encapsular la l√≥gica de c√°lculo por sharp.

### Justificaci√≥n
- Open/Closed Principle: A√±adir sharps sin modificar c√≥digo existente
- Single Responsibility: Cada estrategia maneja una sharp
- Testeable: Cada estrategia se prueba aisladamente

---

## ADR-003: F√≥rmula de Cuota M√≠nima

### Estado
**Aceptada**

### Contexto
La f√≥rmula anterior era incorrecta y aceptaba picks con -3% de profit creyendo que el l√≠mite era -1%.

### Decisi√≥n
Adoptar la f√≥rmula matem√°ticamente correcta:
```python
min_odds = 1 / (1.01 - 1/odd_pinnacle)
```

### Justificaci√≥n
- Corte exacto en -1% de profit
- Impacto econ√≥mico estimado: +900‚Ç¨/mes por cada 1000‚Ç¨/d√≠a apostados

---

## ADR-004: Redis para Deduplicaci√≥n (sin Bloom Filter)

### Estado
**Aceptada** (actualizada - rechaza Bloom Filter)

### Contexto
Necesitamos prevenir duplicados y rebotes. El informe V7 propuso usar Bloom Filter para optimizar latencia.

### Decisi√≥n
Usar **Redis con pipeline batch**, **SIN Bloom Filter**.

### Justificaci√≥n

| Criterio            | Redis Pipeline  | Redis + Bloom     |
| ------------------- | --------------- | ----------------- |
| Latencia            | ~10ms (50 keys) | ~2ms              |
| Falsos positivos    | 0%              | ~1%               |
| Picks perdidos/hora | 0               | ~5 (en 500 picks) |
| Complejidad         | Baja            | Media             |
| Dependencias        | 0 nuevas        | +1 (pybloom)      |

**Factor decisivo**: 1% de falsos positivos = picks v√°lidos con valor NO enviados = p√©rdida de dinero para el apostador. La ganancia de 8ms no justifica el riesgo.

### Consecuencias
**Positivas**: Cero picks perdidos por falsos positivos, simplicidad
**Negativas**: ~8ms m√°s de latencia (insignificante vs API ~200ms)

---

## ADR-005: Chain of Responsibility para Validaci√≥n

### Estado
**Aceptada**

### Contexto
Un pick debe pasar m√∫ltiples validaciones antes de procesarse.

### Decisi√≥n
Implementar **Chain of Responsibility** con orden optimizado (fail-fast).

### Orden de Ejecuci√≥n
1. OddsValidator (CPU, ~0ms)
2. ProfitValidator (CPU, ~0ms)
3. TimeValidator (CPU, ~0ms)
4. DuplicateValidator (I/O Redis, ~5ms)
5. OppositeMarketValidator (I/O Redis, ~5ms)

---

## ADR-006: Multi-Bot Telegram con Heap Priorizado

### Estado
**Aceptada** (actualizada - a√±ade heap)

### Contexto
Telegram tiene rate limits. El informe V7 propuso priorizar env√≠o por profit.

### Decisi√≥n
Pool de 5 bots con **cola de prioridad (heap)** ordenada por profit descendente.

### Justificaci√≥n
- Picks de mayor valor se env√≠an primero
- Si hay congesti√≥n, se descartan los de menor valor
- `heapq` es O(log n) para insert/extract

### Implementaci√≥n
```python
# Heap: (-profit, timestamp, channel_id, message)
# Negativo para que heapq (min-heap) funcione como max-heap

async def enqueue(self, message: str, channel_id: int, profit: float) -> bool:
    if len(self.heap) >= self.max_size:
        min_profit = -self.heap[0][0]
        if profit <= min_profit:
            return False  # Rechazar pick de bajo valor
        heapq.heappop(self.heap)  # Sacar el de menor valor
    
    heapq.heappush(self.heap, (-profit, time.time(), channel_id, message))
    return True
```

### Consecuencias
**Positivas**: Mayor valor enviado primero, degradaci√≥n graceful bajo carga
**Negativas**: Picks de bajo valor pueden perderse bajo congesti√≥n extrema

---

## ADR-007: Persistencia PostgreSQL Diferida

### Estado
**Diferida**

### Contexto
Guardar hist√≥rico permitir√≠a an√°lisis, pero requiere normalizaci√≥n compleja.

### Decisi√≥n
Diferir hasta que el sistema core est√© estable y exista m√≥dulo de normalizaci√≥n.

---

## ADR-008: Value Objects para Datos de Dominio

### Estado
**Aceptada**

### Decisi√≥n
Implementar Value Objects inmutables con validaci√≥n en construcci√≥n (Odds, Profit, MarketType, EventTime).

---

## ADR-009: Cursor Incremental para API

### Estado
**Aceptada** (nueva - del informe V7)

### Contexto
El sistema actual hace polling sin estado, recibiendo picks ya procesados repetidamente.

### Decisi√≥n
Implementar **cursor incremental** usando el campo `sort_by:id` de la API.

### Implementaci√≥n
```python
async def fetch_picks(self) -> List[dict]:
    params = {
        'product': 'surebets',
        'order': 'created_at_desc',
        'min-profit': -1,
        'limit': 5000,
    }
    
    if self.last_cursor:
        params['cursor'] = self.last_cursor
    
    data = await self._request(params)
    
    if data and data.get('records'):
        picks = data['records']
        # Guardar cursor del √∫ltimo pick para siguiente petici√≥n
        last_pick = picks[-1]
        self.last_cursor = f"{last_pick['sort_by']}:{last_pick['id']}"
        await self._persist_cursor()
        return picks
    
    return []
```

### Justificaci√≥n
- Evita recibir picks ya procesados
- Reduce carga en API y en nuestro sistema
- Persistir en Redis permite recuperaci√≥n tras reinicio

### Consecuencias
**Positivas**: Menos datos redundantes, menor procesamiento
**Negativas**: Si cursor se corrompe, puede saltar picks (mitigado con validaci√≥n)

---

## ADR-010: Polling Adaptativo con Backoff

### Estado
**Aceptada** (nueva - del informe V7)

### Contexto
El rate limit de la API (2 req/s) puede saturarse. El informe V7 propuso ajuste din√°mico.

### Decisi√≥n
Implementar **polling adaptativo con backoff exponencial**.

### Implementaci√≥n
```python
class AdaptiveRateLimiter:
    def __init__(self):
        self.base_interval = 0.5
        self.max_interval = 5.0
        self.consecutive_429 = 0
    
    @property
    def current_interval(self) -> float:
        return min(self.max_interval, self.base_interval * (2 ** self.consecutive_429))
    
    def report_success(self):
        self.consecutive_429 = max(0, self.consecutive_429 - 1)
    
    def report_rate_limit(self):
        self.consecutive_429 += 1
```

### Tabla de Intervalos

| Errores 429 | Intervalo |
| ----------- | --------- |
| 0           | 0.5s      |
| 1           | 1.0s      |
| 2           | 2.0s      |
| 3           | 4.0s      |
| 4+          | 5.0s      |

### Justificaci√≥n
- Auto-recuperaci√≥n cuando el l√≠mite se libera
- Sin intervenci√≥n manual
- Backoff exponencial es est√°ndar en la industria

### Consecuencias
**Positivas**: Manejo robusto de rate limits, auto-healing
**Negativas**: Latencia aumenta bajo carga (aceptable - es protecci√≥n)

---

## ADR-011: Cache HTML en Message Formatter

### Estado
**Aceptada** (nueva - del informe V7)

### Contexto
El formateo de mensajes repite c√°lculos para picks del mismo evento.

### Decisi√≥n
Cachear partes est√°ticas del mensaje HTML (teams, tournament, date).

### Implementaci√≥n
```python
def format_message(self, apuesta: dict, contrapartida: dict, profit: float) -> str:
    event_key = self._get_event_key(apuesta)
    
    # Intentar obtener partes cacheadas
    cached = self._get_cached_parts(event_key)
    
    if cached:
        teams_html = cached['teams']
        tournament_html = cached['tournament']
        date_html = cached['date']
    else:
        teams_html = self._format_teams(apuesta)
        tournament_html = self._format_tournament(apuesta)
        date_html = self._format_date(apuesta)
        self._cache_parts(event_key, {
            'teams': teams_html,
            'tournament': tournament_html,
            'date': date_html
        })
    
    # Partes din√°micas (no cachear)
    stake_emoji = self._calculate_stake(profit)
    min_odds = self._calculate_min_odds(contrapartida['value'])
    
    return self._build_message(stake_emoji, teams_html, ...)
```

### Justificaci√≥n
- Ahorra ~2-3ms por pick del mismo evento
- Sin riesgo (TTL corto de 60s)
- Las partes cacheadas no cambian para el mismo evento

### Consecuencias
**Positivas**: Menor latencia en picks consecutivos del mismo evento
**Negativas**: ~1KB memoria por entrada de cache (insignificante)

---

## ADR-012: Rechazo de Bloom Filter

### Estado
**Rechazada**

### Contexto
El informe V7 propuso Bloom Filter para reducir latencia de Redis de ~10ms a ~2ms.

### Decisi√≥n
**NO implementar Bloom Filter**.

### Justificaci√≥n

1. **Falsos positivos = P√©rdida de dinero**
   - Bloom Filter tiene ~1% de falsos positivos
   - Falso positivo = "creo que ya lo envi√©" cuando NO lo enviaste
   - En 500 picks/hora = 5 picks/hora perdidos = ~120 picks/d√≠a
   - Cada pick perdido es una oportunidad de valor NO aprovechada

2. **El cuello de botella NO es Redis**
   - API externa: ~100-300ms
   - Redis: ~10ms
   - Optimizar Redis de 10ms a 2ms es irrelevante (3% del tiempo total)

3. **Complejidad a√±adida**
   - Nueva dependencia (`pybloom-live`)
   - Sincronizaci√≥n bloom ‚Üî Redis
   - El propio informe V7 documenta 4 riesgos altos

### Alternativa implementada
Redis con pipeline batch:
```python
async def exists_batch(self, keys: List[str]) -> Dict[str, bool]:
    async with self.redis.pipeline() as pipe:
        for key in keys:
            pipe.exists(key)
        results = await pipe.execute()
    return dict(zip(keys, results))
```

---

## ADR-013: Rechazo de Fire-and-Forget Redis

### Estado
**Rechazada**

### Contexto
El informe V7 propuso no esperar confirmaci√≥n de Redis para ganar ~5-10ms.

### Decisi√≥n
**NO implementar fire-and-forget**.

### Justificaci√≥n

1. **Race condition documentada**
   > "S√≠ntoma: Dos picks id√©nticos con 50-100ms diferencia"
   
   Escenario:
   ```
   T=0ms:  Pick A llega, check_redis() ‚Üí "no existe"
   T=5ms:  Pick A dispara write_async() (no await)
   T=10ms: Pick A' (mismo evento) llega, check_redis() ‚Üí "no existe" (write a√∫n no complet√≥)
   T=15ms: Pick A' tambi√©n se env√≠a ‚Üí DUPLICADO
   ```

2. **La "mitigaci√≥n" propuesta es un hack**
   ```python
   # Optimistic lock en cache local
   self.local_cache[key] = True  # antes de Redis
   ```
   Solo funciona en un proceso. Si reinicias, pierdes el lock.

3. **Ganancia marginal**
   - Ahorra ~5-10ms por pick
   - Pero introduce duplicados que cuestan dinero al apostador

### Alternativa implementada
```python
async def mark_sent(self, pick: Pick, ttl: int) -> bool:
    try:
        async with asyncio.timeout(0.1):  # 100ms m√°ximo
            await self.redis.setex(key, ttl, time.time())
            return True
    except asyncio.TimeoutError:
        logger.warning(f"Redis timeout para {key}")
        return False
```

---

## ADR-014: Procesamiento con asyncio.gather (sin workers)

### Estado
**Aceptada** (nueva - del informe V7)

### Contexto
V6 usa 3 tipos de workers con colas internas:
- validation_queue ‚Üí validation_workers
- redis_queue ‚Üí redis_workers
- telegram_queue ‚Üí telegram_workers

### Decisi√≥n
Eliminar workers y colas internas, usar **asyncio.gather** para procesamiento paralelo.

### Implementaci√≥n
```python
# V6 (workers/colas)
await self.validation_queue.put(pick)
# ... pick viaja por 3 colas ...

# V2.0 (gather directo)
async def process_batch(self, picks: List[dict]) -> List[ProcessedPick]:
    tasks = [self._process_single(pick) for pick in picks]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return [r for r in results if isinstance(r, ProcessedPick)]
```

### Justificaci√≥n
- Las colas internas a√±aden latencia (~5-10ms por cola)
- `asyncio.gather` es suficiente para el volumen
- Simplifica debugging (sin estados intermedios)
- Reduce complejidad de c√≥digo

### Consecuencias
**Positivas**: Menor latencia, c√≥digo m√°s simple, debugging m√°s f√°cil
**Negativas**: Menos control granular sobre backpressure (aceptable para volumen actual)

---

## ADR-015: Filtrado en Origen (API Parameters)

### Estado
**Aceptada** (nueva - an√°lisis de optimizaci√≥n API)

### Contexto
El an√°lisis de la API de apostasseguras.com revel√≥ que solo us√°bamos una fracci√≥n de los par√°metros de filtrado disponibles. Esto resultaba en recibir ~5000 picks y filtrar ~80% en c√≥digo.

### Decisi√≥n
Implementar **filtrado en origen** usando todos los par√°metros de API disponibles.

### Par√°metros Implementados

| Par√°metro              | Valor   | Prop√≥sito                                |
| ---------------------- | ------- | ---------------------------------------- |
| `outcomes`             | `2`     | Solo surebets de 2 patas                 |
| `min-profit`           | `-1`    | Profit m√≠nimo                            |
| `max-profit`           | `25`    | Profit m√°ximo                            |
| `min-odds`             | `1.10`  | Cuota m√≠nima                             |
| `max-odds`             | `9.99`  | Cuota m√°xima                             |
| `hide-different-rules` | `true`  | Excluir surebets con reglas conflictivas |
| `startAge`             | `PT10M` | Solo surebets < 10 min antig√ºedad        |
| `oddsFormat`           | `eu`    | Formato decimal expl√≠cito                |



### Justificaci√≥n

**Impacto cuantificado**:
- **Antes**: Recib√≠amos ~5000 picks, filtrar en c√≥digo, ~500 v√°lidos
- **Despu√©s**: Recibimos ~1000-2000 picks (pre-filtrados), ~500 v√°lidos
- **Ahorro**: ~60-70% menos datos a procesar

**Beneficios**:
1. Menor consumo de ancho de banda
2. Menor carga de CPU en validaciones
3. Menor uso de memoria
4. Menor latencia end-to-end

### Consecuencias
**Positivas**: Reducci√≥n significativa de datos procesados, menor latencia
**Negativas**: Mayor dependencia de la estabilidad de par√°metros de API

| Validador       | Antes               | Despu√©s               |
| --------------- | ------------------- | --------------------- |
| OddsValidator   | Validaci√≥n primaria | Optional safety check |
| ProfitValidator | Validaci√≥n primaria | Optional safety check |

---

## ADR-016: Sistema de Suscripciones Automatizado

### Estado
**Propuesta**

### Contexto
Implementaci√≥n de sistema de suscripciones con canales exclusivos por cliente. Flujo autom√°tico: selecci√≥n ‚Üí pago ‚Üí provisioning ‚Üí acceso.

### Decisiones Clave
- **Telegram**: Userbot con Telethon (MTProto) para crear canales program√°ticamente
- **Pagos**: Stripe Checkout + Billing con webhooks
- **Web**: FastAPI + Jinja2 para landing page y webhooks
- **Base de Datos**: PostgreSQL con tablas `customers`, `service_plans`, `subscriptions`, `telegram_channels`

### Componentes Nuevos
- `src/subscriptions/` - M√≥dulo completo de suscripciones
- `src/web/` - Landing page y webhooks
- `migrations/` - Scripts SQL para nuevas tablas

### Documentaci√≥n Detallada
üìÑ **[ADR-016-Subscriptions.md](./ADRs/ADR-016-Subscriptions.md)** - Documento completo con:
- An√°lisis de alternativas
- Arquitectura de bots
- Modelo de datos SQL
- Flujo de provisioning
- Estimaciones y riesgos

---

## Ap√©ndice A: Resumen de Decisiones V7

| Propuesta V7           | Decisi√≥n    | ADR                       |
| ---------------------- | ----------- | ------------------------- |
| Bloom Filter           | ‚ùå Rechazada | ADR-012                   |
| Fire-and-forget Redis  | ‚ùå Rechazada | ADR-013                   |
| Estructura carpetas V7 | ‚ùå Rechazada | (usar Clean Architecture) |
| Cursor incremental     | ‚úÖ Aceptada  | ADR-009                   |
| Polling adaptativo     | ‚úÖ Aceptada  | ADR-010                   |
| Cache HTML             | ‚úÖ Aceptada  | ADR-011                   |
| Heap priorizado        | ‚úÖ Aceptada  | ADR-006 (actualizado)     |
| Eliminar workers       | ‚úÖ Aceptada  | ADR-014                   |
| Filtrado en origen     | ‚úÖ Aceptada  | ADR-015                   |

---

## Ap√©ndice B: Plantilla para Nuevas Decisiones

```markdown
## ADR-XXX: [T√≠tulo]

### Estado
[Propuesta | Aceptada | Rechazada | Deprecada | Sustituida por ADR-YYY]

### Contexto
[Descripci√≥n del problema y contexto]

### Decisi√≥n
[La decisi√≥n tomada]

### Justificaci√≥n
[Por qu√© esta decisi√≥n sobre las alternativas]

### Consecuencias
**Positivas**: ...
**Negativas**: ...

### Alternativas Consideradas
[Otras opciones evaluadas y por qu√© se descartaron]
```

---

## Historial de Cambios

| Fecha    | Versi√≥n | Cambios                                                                      | Autor          |
| -------- | ------- | ---------------------------------------------------------------------------- | -------------- |
| Dic 2024 | 1.0     | Documento inicial con 8 ADRs                                                 | Equipo Retador |
| Dic 2024 | 2.0     | Integraci√≥n selectiva V7: +6 ADRs (009-014), actualizaci√≥n ADR-004 y ADR-006 | Equipo Retador |